{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "n_components = 256 #32\n",
    "\n",
    "corpus_all = fetch_20newsgroups(subset=\"all\", remove=('headers', 'footers', 'quotes'))\n",
    "corpus_train, corpus_test, y_train, y_test = train_test_split(corpus_all.data, corpus_all.target, test_size=0.25, random_state=0)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=max_features, norm=None),\n",
    "    Normalizer(),\n",
    "    StandardScaler(copy=False, with_mean=False),\n",
    "    Normalizer(),\n",
    "    TruncatedSVD(n_components=n_components),\n",
    "    Normalizer()\n",
    ")\n",
    "\n",
    "X_train = pipeline.fit_transform(corpus_train)\n",
    "X_test = pipeline.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm: KMeans\n",
      "  v-measure:    0.47\n",
      "  homogeneity:  0.46\n",
      "  completeness: 0.49\n",
      "\n",
      "algorithm: MiniBatchKMeans\n",
      "  v-measure:    0.39\n",
      "  homogeneity:  0.38\n",
      "  completeness: 0.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import v_measure_score, homogeneity_score, completeness_score\n",
    "from sklearn.cluster import MiniBatchKMeans, AgglomerativeClustering, DBSCAN, KMeans, Birch, MeanShift\n",
    "\n",
    "algos = [\n",
    "    KMeans(n_init=10, n_clusters=20),\n",
    "    MiniBatchKMeans(n_init=10, n_clusters=20),\n",
    "    #Birch(n_clusters=20),\n",
    "    #MeanShift()\n",
    "    #AgglomerativeClustering(n_clusters=20),\n",
    "    #DBSCAN()\n",
    "]\n",
    "\n",
    "while algos:\n",
    "    algo = algos.pop(0)\n",
    "    y_predict = algo.fit_predict(X_train)\n",
    "    print(\"algorithm: %s\" % algo.__class__.__name__)\n",
    "    print(\"  v-measure:    %0.2f\" % v_measure_score(y_train, y_predict))\n",
    "    print(\"  homogeneity:  %0.2f\" % homogeneity_score(y_train, y_predict))\n",
    "    print(\"  completeness: %0.2f\" % completeness_score(y_train, y_predict))\n",
    "    print(\"\")\n",
    "    del algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.57      0.53      0.55       205\n",
      "           comp.graphics       0.64      0.60      0.62       245\n",
      " comp.os.ms-windows.misc       0.68      0.63      0.65       250\n",
      "comp.sys.ibm.pc.hardware       0.65      0.64      0.65       243\n",
      "   comp.sys.mac.hardware       0.74      0.70      0.72       255\n",
      "          comp.windows.x       0.74      0.78      0.76       240\n",
      "            misc.forsale       0.77      0.77      0.77       249\n",
      "               rec.autos       0.46      0.75      0.57       219\n",
      "         rec.motorcycles       0.78      0.74      0.76       246\n",
      "      rec.sport.baseball       0.83      0.83      0.83       227\n",
      "        rec.sport.hockey       0.89      0.87      0.88       287\n",
      "               sci.crypt       0.78      0.78      0.78       234\n",
      "         sci.electronics       0.64      0.61      0.63       247\n",
      "                 sci.med       0.82      0.81      0.82       250\n",
      "               sci.space       0.75      0.78      0.76       240\n",
      "  soc.religion.christian       0.66      0.80      0.72       250\n",
      "      talk.politics.guns       0.67      0.71      0.69       211\n",
      "   talk.politics.mideast       0.79      0.83      0.81       246\n",
      "      talk.politics.misc       0.64      0.57      0.60       209\n",
      "      talk.religion.misc       0.53      0.17      0.26       159\n",
      "\n",
      "             avg / total       0.71      0.71      0.70      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=corpus.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.57      0.52      0.55       205\n",
      "           comp.graphics       0.70      0.54      0.61       245\n",
      " comp.os.ms-windows.misc       0.61      0.67      0.63       250\n",
      "comp.sys.ibm.pc.hardware       0.71      0.44      0.54       243\n",
      "   comp.sys.mac.hardware       0.55      0.73      0.63       255\n",
      "          comp.windows.x       0.71      0.77      0.74       240\n",
      "            misc.forsale       0.83      0.73      0.78       249\n",
      "               rec.autos       0.78      0.64      0.70       219\n",
      "         rec.motorcycles       0.72      0.76      0.74       246\n",
      "      rec.sport.baseball       0.84      0.84      0.84       227\n",
      "        rec.sport.hockey       0.91      0.86      0.88       287\n",
      "               sci.crypt       0.81      0.75      0.78       234\n",
      "         sci.electronics       0.58      0.64      0.60       247\n",
      "                 sci.med       0.88      0.78      0.83       250\n",
      "               sci.space       0.73      0.78      0.76       240\n",
      "  soc.religion.christian       0.71      0.74      0.73       250\n",
      "      talk.politics.guns       0.53      0.74      0.62       211\n",
      "   talk.politics.mideast       0.86      0.78      0.81       246\n",
      "      talk.politics.misc       0.58      0.56      0.57       209\n",
      "      talk.religion.misc       0.16      0.20      0.18       159\n",
      "\n",
      "             avg / total       0.70      0.69      0.69      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = OneVsRestClassifier(SGDClassifier(loss=\"hinge\", random_state=0)).fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=corpus.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(text, max_len=300):\n",
    "    text = \" \".join(text.strip().split())\n",
    "    if max_len:\n",
    "        text = text if len(text) < max_len else text[:max_len] + \" [...]\"\n",
    "    return text\n",
    "\n",
    "def find_similar(text, topn=10, max_len=300):\n",
    "    print(\"SEARCH TEXT:\")\n",
    "    print(clean_text(text, max_len))\n",
    "    print(\"\")\n",
    "    x_search = pipeline.transform([text])\n",
    "    scores = x_search.dot(X_train.T)[0]\n",
    "    index = np.argsort(scores)[::-1][:topn]\n",
    "    for num, i in enumerate(index):\n",
    "        print(\"RESULT %d [score: %0.2f, category: %s]:\" % ((num+1), scores[i], corpus.target_names[y_train[i]]))\n",
    "        print(clean_text(corpus_train[i], max_len))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TEXT:\n",
      "On the other hand, Rush made an interesting point: The Democrats ran one of their best campaigns in years against a pathetic Republican and a paranoiac and still only pulled 43% of the vote, lost 10 seats in the House, and gained 0 seats in the Senate. 1994 might be pretty interesting. Clueless of the world, take heart! 57% of the electorate is willing to vote for \"a pathetic Republican and a paranoiac\"!!\n",
      "\n",
      "RESULT 1 [score: 0.67, category: talk.politics.guns]:\n",
      "The Brady Bill passed the House in 1992, but failed to reach a vote in the Senate. As such, it never reached Bush. (Sarah Brady's condemnation not-withstanding). It'll probably pass the House again, and will probably pass the Senate if they can get it to a vote. Whether of not they'll be busy with other things will be the question. I don't expect gung-ho opposition on the part of Senate Republicans, since they won't want to over-use their fillibuster trump card.\n",
      "\n",
      "\n",
      "RESULT 2 [score: 0.63, category: talk.politics.misc]:\n",
      "THE WHITE HOUSE Office of the Press Secretary ____________________________________________________________________ For Immediate Release April 5, 1993 REMARKS BY THE PRESIDENT EN ROUTE TO CAMDEN YARDS FOR ORIOLES OPENING DAY GAME MARC Train En Route to Camden Yards 11:45 A.M. EDT Q Mr. President, what do you think of Jesse Jackson's protest today? THE PRESIDENT: I think it's an informational protest. I think it's fine. The owners put out a statement few days ago, which they say was the first step in, you know, efforts to increase minority ownership and minority increases in management. I think we should. I'm encouraged by Don Baylor's appointment out in Colorado. And I think it's time to make a move on that front. So, I think it's a legitimate issue, and I think it's -- like I said, it's an informational picket and not an attempt to get people not to go to the game. So, I think it's good. Q Do you think they're moving fast enough? THE PRESIDENT: Well, I think that it was a good first step. And I think you'll see some movement now. And I think it's an issue that deserves some attention, and they're obviously going to give it some. And I think that Reverend Jackson being out there will highlight the issue. So I think it's fine. Q Mr. President, how about the logjam in the Senate on the economic stimulus plan? Do you think they'll be able to break that and get cloture? THE PRESIDENT: I don't know, we're working at it. I mean, it's a classic -- there was an article in the paper today, one of the papers I saw, which pretty well summed it up. They said, you know, this is a -- it's just a political power play. In the Senate the majority does not rule. It's not like the country. It's not like the -- it's not like the House. If the minority chooses, they can stop majority rule. And that's what they're doing. There are a lot of Republican senators who have told people that they might vote for the stimulus program but there's enormous partisan political pressure not to do it. And, of course, what it means is that in this time when no new jobs are being created, even though there seems to be an economic recovery, it means that for political purposes they're willing to deny jobs to places like Baltimore and Dallas and Houston and Pittsburgh and Philadelphia and Portland and Seattle. It's very sad. I mean, the block grant program was designed to create jobs in a hurry based on local priorities, and it's one that the Republicans had always championed. Just about the only Democrat champions of the program were people like me who were out there at the grassroots level, governors and senators. I just think it's real sad that they have chosen to exert the minority muscle in a way that will keep Americans out of work. I think it's a mistake. THE PRESS: Thank you.\n",
      "\n",
      "\n",
      "RESULT 3 [score: 0.62, category: talk.politics.misc]:\n",
      "[of who else but President of the United States William Jefferson Clinton.] Tsk. Surely you don't wish for the Democrats to destroy our beloved country just so your party can get some trivial political advantage? That's rather a petty way to think. (Not that this pettiness doesn't extend all the way to the U.S. Senate, I've noticed...) While Bush was president, I kept hoping and praying that he'd wise up. I couldn't stand the man, but I wish he'd done a decent job; if so, we might not be in the mess we are now, and that would be a small price to pay for suffering through another term of Republican control. Similarily, YOU should be hoping and praying that Clinton does a good job. Even if you're certain he won't.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_similar(corpus_test[300], topn=3, max_len=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
